{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay, \n",
    "    classification_report,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# Custom imports\n",
    "from utils.gpu_utils import CheckGPU, CheckCUDA, CheckGPUBrief, get_device\n",
    "from utils.guava_dataset import (\n",
    "    GuavaDataset, \n",
    "    load_guava_info, \n",
    "    print_guava_summary,\n",
    "    get_class_labels\n",
    ")\n",
    "from utils.dataset_counter import CountDataset, PrintClassBalance\n",
    "\n",
    "print(\"‚úÖ All libraries and custom modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc56933",
   "metadata": {},
   "source": [
    "#### Detect GPU Available, Details, Cuda, and cuDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From utils.gpu_utils\n",
    "CheckGPU()\n",
    "CheckCUDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc7177",
   "metadata": {},
   "source": [
    "### Global Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# GLOBAL CONFIGURATION\n",
    "# ============================\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_DIR = \"../dataset\"\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"Train\")\n",
    "TEST_DIR = os.path.join(DATASET_DIR, \"Test\")\n",
    "\n",
    "# We'll create validation from training set\n",
    "VALIDATION_SPLIT = 0.15  # 15% of training data for validation (85% train, 15% val)\n",
    "\n",
    "# Augmentation settings\n",
    "USE_AUGMENTATION = True\n",
    "\n",
    "# Weighted sampling for class imbalance\n",
    "USE_WEIGHTED_SAMPLER = True\n",
    "\n",
    "# Normalization values\n",
    "# Option 1: Use ImageNet pretrained values (recommended for transfer learning)\n",
    "USE_IMAGENET_NORM = True\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Option 2: Compute from Guava dataset (set USE_IMAGENET_NORM = False to use these)\n",
    "# These will be computed later if needed\n",
    "GUAVA_MEAN = [0.5, 0.5, 0.5]  # Placeholder - compute from dataset\n",
    "GUAVA_STD = [0.25, 0.25, 0.25]  # Placeholder - compute from dataset\n",
    "\n",
    "# Set normalization based on choice\n",
    "if USE_IMAGENET_NORM:\n",
    "    NORMALIZE_MEAN = IMAGENET_MEAN\n",
    "    NORMALIZE_STD = IMAGENET_STD\n",
    "    print(\"üìä Using ImageNet normalization values (recommended for transfer learning)\")\n",
    "else:\n",
    "    NORMALIZE_MEAN = GUAVA_MEAN\n",
    "    NORMALIZE_STD = GUAVA_STD\n",
    "    print(\"üìä Using Guava-specific normalization values\")\n",
    "\n",
    "# Image settings\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# Batch size - adjust based on your GPU memory\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Number of classes - UPDATE THIS based on your dataset\n",
    "# e.g., if you have day_01, day_02, ..., day_07 folders, set NUM_CLASSES = 7\n",
    "NUM_CLASSES = None  # Will be auto-detected from dataset\n",
    "\n",
    "# Model Architecture Selection\n",
    "# Options: 'resnet50' or 'efficientnet_b3'\n",
    "MODEL_ARCH = 'resnet50'  # Change this to 'efficientnet_b3' to switch models\n",
    "\n",
    "# Model save path\n",
    "MODEL_SAVE_DIR = \"../models\"\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"\\n‚úÖ Global configuration set successfully!\")\n",
    "print(f\"   Dataset: {DATASET_DIR}\")\n",
    "print(f\"   Model Architecture: {MODEL_ARCH.upper()}\")\n",
    "print(f\"   Image Size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Validation Split: {VALIDATION_SPLIT*100:.0f}%\")\n",
    "print(f\"   Augmentation: {'ENABLED' if USE_AUGMENTATION else 'DISABLED'}\")\n",
    "print(f\"   Weighted Sampler: {'ENABLED' if USE_WEIGHTED_SAMPLER else 'DISABLED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81d299",
   "metadata": {},
   "source": [
    "### Guava Dataset Analysis & Information\n",
    "\n",
    "Load and analyze the Guava Ripeness dataset structure, class distribution, and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Guava dataset information\n",
    "print(\"üîç Loading Guava dataset information...\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(f\"‚ùå Training directory not found: {TRAIN_DIR}\")\n",
    "    print(\"\\nüìù Please organize your dataset as follows:\")\n",
    "    print(\"   dataset/\")\n",
    "    print(\"   ‚îú‚îÄ‚îÄ Train/\")\n",
    "    print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ day_01/  (or your age class names)\")\n",
    "    print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ day_02/\")\n",
    "    print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ ...\")\n",
    "    print(\"   ‚îî‚îÄ‚îÄ Test/\")\n",
    "    print(\"       ‚îú‚îÄ‚îÄ day_01/\")\n",
    "    print(\"       ‚îî‚îÄ‚îÄ ...\")\n",
    "else:\n",
    "    dataset_info = load_guava_info(DATASET_DIR)\n",
    "    print_guava_summary(dataset_info)\n",
    "    \n",
    "    # Auto-detect number of classes\n",
    "    NUM_CLASSES = dataset_info['num_classes']\n",
    "    CLASS_NAMES = dataset_info['classes']\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset information loaded successfully!\")\n",
    "    print(f\"   Detected {NUM_CLASSES} classes: {CLASS_NAMES}\")\n",
    "    \n",
    "    # Count dataset details\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìÅ TRAINING SET DETAILS\")\n",
    "    train_info = CountDataset(TRAIN_DIR)\n",
    "    \n",
    "    if os.path.exists(TEST_DIR):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìÅ TEST SET DETAILS\")\n",
    "        test_info = CountDataset(TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121d540",
   "metadata": {},
   "source": [
    "### Visualize Sample Images from Dataset\n",
    "\n",
    "Display sample guava images from each class to understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print(\"üñºÔ∏è  Displaying sample guava images from dataset...\")\n",
    "\n",
    "if NUM_CLASSES is None:\n",
    "    print(\"‚ùå Dataset not loaded. Please run the previous cell first.\")\n",
    "else:\n",
    "    # Calculate grid size\n",
    "    num_samples = min(NUM_CLASSES, 12)  # Show up to 12 samples\n",
    "    cols = min(4, num_samples)\n",
    "    rows = (num_samples + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.ravel()\n",
    "    \n",
    "    for idx, class_name in enumerate(CLASS_NAMES[:num_samples]):\n",
    "        class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "        \n",
    "        # Get a random image from this class\n",
    "        images = [f for f in os.listdir(class_dir) \n",
    "                  if os.path.splitext(f)[1].lower() in ['.jpg', '.jpeg', '.png', '.bmp']]\n",
    "        \n",
    "        if images:\n",
    "            sample_img = random.choice(images)\n",
    "            img_path = os.path.join(class_dir, sample_img)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].axis('off')\n",
    "            axes[idx].set_title(f'{class_name}\\n{img.size[0]}x{img.size[1]}px', \n",
    "                               fontsize=10, fontweight='bold')\n",
    "        else:\n",
    "            axes[idx].text(0.5, 0.5, 'No images', ha='center', va='center')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(num_samples, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Guava Images by Ripeness Class', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Sample visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d552b",
   "metadata": {},
   "source": [
    "### Data Augmentation & Transforms\n",
    "\n",
    "Define transforms for training (with augmentation) and validation/test sets.\n",
    "Guava-specific augmentations optimized for fruit ripeness recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_AUGMENTATION:\n",
    "    # Training augmentation - optimized for fruit images\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT + 32, IMG_WIDTH + 32)),  # Resize slightly larger\n",
    "        transforms.RandomCrop((IMG_HEIGHT, IMG_WIDTH)),  # Random crop to target size\n",
    "        # Geometric augmentations\n",
    "        transforms.RandomRotation(30),  # Fruits can be at various angles\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        # Color augmentations (important for ripeness detection)\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.4, hue=0.1),\n",
    "        # Random perspective (simulates different viewing angles)\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "        # Convert to tensor\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize\n",
    "        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),\n",
    "        # Random erasing (simulates occlusion)\n",
    "        transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))\n",
    "    ])\n",
    "    print(\"‚úÖ Training augmentation ENABLED\")\n",
    "    print(\"   - Rotation: ¬±30¬∞\")\n",
    "    print(\"   - Random crop: Yes\")\n",
    "    print(\"   - Horizontal/Vertical flip\")\n",
    "    print(\"   - Color jitter: brightness/contrast/saturation/hue\")\n",
    "    print(\"   - Perspective distortion\")\n",
    "    print(\"   - Random erasing\")\n",
    "else:\n",
    "    # No augmentation\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
    "    ])\n",
    "    print(\"‚ö†Ô∏è  Training augmentation DISABLED\")\n",
    "\n",
    "# Validation and test transforms (no augmentation)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD)\n",
    "])\n",
    "\n",
    "print(f\"\\n‚úÖ Transforms defined successfully!\")\n",
    "print(f\"   Target size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"   Normalization: Mean={NORMALIZE_MEAN}, Std={NORMALIZE_STD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abefe5a9",
   "metadata": {},
   "source": [
    "### Load Guava Datasets\n",
    "\n",
    "Load the training and test sets.\n",
    "Create validation set by splitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is None:\n",
    "    print(\"‚ùå Dataset not loaded. Please run the dataset analysis cell first.\")\n",
    "else:\n",
    "    # Load full training dataset (will split into train/val)\n",
    "    print(\"üìÇ Loading Guava training dataset...\")\n",
    "    full_train_dataset = GuavaDataset(\n",
    "        root_dir=TRAIN_DIR,\n",
    "        transform=None,  # Will assign transforms after split\n",
    "    )\n",
    "    \n",
    "    # Load test dataset if exists\n",
    "    if os.path.exists(TEST_DIR):\n",
    "        print(\"üìÇ Loading Guava test dataset...\")\n",
    "        test_dataset = GuavaDataset(\n",
    "            root_dir=TEST_DIR,\n",
    "            transform=val_test_transforms,  # No augmentation for test\n",
    "            class_mapping=full_train_dataset.class_to_idx  # Use same class mapping\n",
    "        )\n",
    "        num_test = len(test_dataset)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No separate test set found. Will use validation set for testing.\")\n",
    "        test_dataset = None\n",
    "        num_test = 0\n",
    "    \n",
    "    num_total_train = len(full_train_dataset)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Datasets loaded successfully!\")\n",
    "    print(f\"   Training samples (before split): {num_total_train:,}\")\n",
    "    print(f\"   Test samples: {num_test:,}\")\n",
    "    \n",
    "    # Split training into train and validation\n",
    "    val_size = int(VALIDATION_SPLIT * num_total_train)\n",
    "    train_size = num_total_train - val_size\n",
    "    \n",
    "    # Use random_split to create train/val indices\n",
    "    train_subset, val_subset = random_split(\n",
    "        full_train_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(SEED)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training data split completed:\")\n",
    "    print(f\"   üîπ Train: {train_size:,} samples ({(1-VALIDATION_SPLIT)*100:.0f}%)\")\n",
    "    print(f\"   üîπ Validation: {val_size:,} samples ({VALIDATION_SPLIT*100:.0f}%)\")\n",
    "    print(f\"   üîπ Test: {num_test:,} samples (separate set)\")\n",
    "    \n",
    "    # Assign transforms to subsets\n",
    "    # Note: This will apply to all samples, including val subset\n",
    "    # We need to handle this differently\n",
    "    \n",
    "    print(f\"\\n‚úÖ Transforms will be assigned in DataLoader creation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875425ac",
   "metadata": {},
   "source": [
    "### Compute Class Weights for Imbalanced Data\n",
    "\n",
    "Calculate class weights to handle potential class imbalance in the Guava dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b4f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is None:\n",
    "    print(\"‚ùå Dataset not loaded.\")\n",
    "else:\n",
    "    # Get class distribution from training data\n",
    "    class_counts_dict = full_train_dataset.get_class_counts()\n",
    "    class_counts = np.array([class_counts_dict.get(i, 0) for i in range(NUM_CLASSES)])\n",
    "    \n",
    "    print(f\"üìä Class distribution in training set:\")\n",
    "    print(f\"   Total classes: {len(class_counts)}\")\n",
    "    print(f\"   Most populated class: {class_counts.max():,} samples\")\n",
    "    print(f\"   Least populated class: {class_counts.min():,} samples\")\n",
    "    print(f\"   Average per class: {class_counts.mean():.1f} samples\")\n",
    "    \n",
    "    if class_counts.min() > 0:\n",
    "        imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "        print(f\"   Imbalance ratio: {imbalance_ratio:.2f}x\")\n",
    "    else:\n",
    "        imbalance_ratio = float('inf')\n",
    "        print(f\"   ‚ö†Ô∏è  Warning: Some classes have 0 samples!\")\n",
    "    \n",
    "    # Compute class weights (inverse frequency)\n",
    "    class_weights = 1.0 / (class_counts + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_weights)  # Normalize\n",
    "    \n",
    "    print(f\"\\nüìê Class weights computed:\")\n",
    "    print(f\"   Min weight: {class_weights.min():.4f}\")\n",
    "    print(f\"   Max weight: {class_weights.max():.4f}\")\n",
    "    print(f\"   Weight ratio: {class_weights.max() / class_weights.min():.2f}x\")\n",
    "    \n",
    "    # Create sample weights for WeightedRandomSampler\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        # Get labels from training subset\n",
    "        train_indices = train_subset.indices\n",
    "        train_labels = [full_train_dataset.samples[idx][1] for idx in train_indices]\n",
    "        sample_weights = [class_weights[label] for label in train_labels]\n",
    "        \n",
    "        print(f\"\\n‚úÖ Weighted sampler initialized for {len(sample_weights):,} training samples\")\n",
    "    else:\n",
    "        sample_weights = None\n",
    "        print(\"\\n‚ö†Ô∏è  Weighted sampler DISABLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b2b7b",
   "metadata": {},
   "source": [
    "### Create DataLoaders\n",
    "\n",
    "Initialize PyTorch DataLoaders with appropriate batch size and sampling strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom wrapper datasets to apply different transforms\n",
    "class TransformDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original item\n",
    "        img_path, label = self.subset.dataset.samples[self.subset.indices[idx]]\n",
    "        from PIL import Image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "\n",
    "if NUM_CLASSES is None:\n",
    "    print(\"‚ùå Dataset not loaded.\")\n",
    "else:\n",
    "    # Create wrapped datasets with appropriate transforms\n",
    "    train_dataset_wrapped = TransformDataset(train_subset, train_transforms)\n",
    "    val_dataset_wrapped = TransformDataset(val_subset, val_test_transforms)\n",
    "    \n",
    "    # Create training DataLoader\n",
    "    if USE_WEIGHTED_SAMPLER and sample_weights is not None:\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset_wrapped,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            sampler=sampler,\n",
    "            num_workers=0,  # Set to 0 for Windows compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        print(f\"‚úÖ Train DataLoader: {len(train_subset):,} samples with WeightedRandomSampler\")\n",
    "    else:\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset_wrapped,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        print(f\"‚úÖ Train DataLoader: {len(train_subset):,} samples with shuffle=True\")\n",
    "    \n",
    "    # Create validation DataLoader\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_wrapped,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    print(f\"‚úÖ Validation DataLoader: {len(val_subset):,} samples\")\n",
    "    \n",
    "    # Create test DataLoader if test set exists\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        print(f\"‚úÖ Test DataLoader: {len(test_dataset):,} samples\")\n",
    "    else:\n",
    "        test_loader = val_loader  # Use validation as test\n",
    "        print(f\"‚ö†Ô∏è  Using validation set as test set\")\n",
    "    \n",
    "    print(f\"\\nüì¶ Batch configuration:\")\n",
    "    print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"   Train batches: {len(train_loader)}\")\n",
    "    print(f\"   Validation batches: {len(val_loader)}\")\n",
    "    print(f\"   Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf2d8c",
   "metadata": {},
   "source": [
    "### Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is not None:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä PREPROCESSING SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Dataset:':<30} Guava Ripeness (Age Classification)\")\n",
    "    print(f\"{'Total Classes:':<30} {NUM_CLASSES}\")\n",
    "    print(f\"{'Training Samples:':<30} {train_size:,}\")\n",
    "    print(f\"{'Validation Samples:':<30} {val_size:,}\")\n",
    "    print(f\"{'Test Samples:':<30} {num_test:,}\")\n",
    "    print(f\"{'Total Samples:':<30} {train_size + val_size + num_test:,}\")\n",
    "    print(f\"\\n{'Image Processing:':<30}\")\n",
    "    print(f\"  {'- Target Size:':<28} {IMG_HEIGHT}x{IMG_WIDTH} pixels\")\n",
    "    print(f\"  {'- Normalization:':<28} {'ImageNet' if USE_IMAGENET_NORM else 'Guava'}\")\n",
    "    print(f\"\\n{'Augmentation:':<30} {'ENABLED' if USE_AUGMENTATION else 'DISABLED'}\")\n",
    "    if USE_AUGMENTATION:\n",
    "        print(f\"  - Rotation, Flip, Color Jitter, Perspective, Erasing\")\n",
    "    print(f\"\\n{'Class Balancing:':<30}\")\n",
    "    print(f\"  {'- Weighted Sampling:':<28} {'ENABLED' if USE_WEIGHTED_SAMPLER else 'DISABLED'}\")\n",
    "    if 'imbalance_ratio' in dir() and imbalance_ratio != float('inf'):\n",
    "        print(f\"  {'- Class Imbalance Ratio:':<28} {imbalance_ratio:.2f}x\")\n",
    "    print(f\"\\n{'Batch Configuration:':<30}\")\n",
    "    print(f\"  {'- Batch Size:':<28} {BATCH_SIZE}\")\n",
    "    print(f\"  {'- Train Batches/Epoch:':<28} {len(train_loader)}\")\n",
    "    print(f\"  {'- Val Batches/Epoch:':<28} {len(val_loader)}\")\n",
    "    print(f\"  {'- Test Batches:':<28} {len(test_loader)}\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚úÖ Preprocessing complete! Ready for model training.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385984e",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283027d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# MODEL TRAINING CONFIGURATION\n",
    "# ============================\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 0.0001\n",
    "MAX_EPOCHS = 30  # Maximum training epochs\n",
    "WEIGHT_DECAY = 1e-4  # L2 regularization to prevent overfitting\n",
    "DROPOUT_RATE = 0.4  # Dropout in classifier head\n",
    "\n",
    "# Early stopping\n",
    "EARLY_STOPPING_PATIENCE = 10  # Stop if no improvement for 10 epochs\n",
    "\n",
    "# Gradient clipping\n",
    "MAX_GRAD_NORM = 1.0  # Prevent exploding gradients\n",
    "\n",
    "# Training history dictionary (global)\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"train_top5_acc\": [],\n",
    "    \"val_top5_acc\": [],\n",
    "    \"learning_rates\": []\n",
    "}\n",
    "\n",
    "print(\"üéØ Training Configuration:\")\n",
    "print(f\"   Model: {MODEL_ARCH.upper()}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   Weight Decay: {WEIGHT_DECAY}\")\n",
    "print(f\"   Dropout Rate: {DROPOUT_RATE}\")\n",
    "print(f\"   Max Epochs: {MAX_EPOCHS}\")\n",
    "print(f\"   Early Stopping Patience: {EARLY_STOPPING_PATIENCE}\")\n",
    "print(f\"   Classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc48ae",
   "metadata": {},
   "source": [
    "### Load Pretrained Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efcfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model based on MODEL_ARCH configuration\n",
    "CheckCUDA()\n",
    "device = get_device()\n",
    "print(f\"\\nüñ•Ô∏è  Using device: {device}\")\n",
    "\n",
    "if NUM_CLASSES is None:\n",
    "    print(\"‚ùå NUM_CLASSES not set. Please run dataset analysis first.\")\n",
    "else:\n",
    "    if MODEL_ARCH == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        print(\"\\n‚úÖ Pre-trained ResNet50 loaded (weights: IMAGENET1K_V1)\")\n",
    "        \n",
    "        # Replace classifier head with dropout\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(DROPOUT_RATE),\n",
    "            nn.Linear(in_features, NUM_CLASSES)\n",
    "        )\n",
    "        print(f\"‚úÖ Classifier replaced: {in_features} ‚Üí Dropout({DROPOUT_RATE}) ‚Üí {NUM_CLASSES} classes\")\n",
    "    \n",
    "    elif MODEL_ARCH == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "        print(\"‚úÖ Pre-trained EfficientNet-B3 loaded (weights: IMAGENET1K_V1)\")\n",
    "        \n",
    "        # Replace classifier head with dropout\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(DROPOUT_RATE, inplace=True),\n",
    "            nn.Linear(in_features, NUM_CLASSES)\n",
    "        )\n",
    "        print(f\"‚úÖ Classifier replaced: {in_features} ‚Üí Dropout({DROPOUT_RATE}) ‚Üí {NUM_CLASSES} classes\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model architecture: {MODEL_ARCH}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nüìä Model Statistics:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c3a93",
   "metadata": {},
   "source": [
    "### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is not None:\n",
    "    # Loss function with optional class weights\n",
    "    if USE_WEIGHTED_SAMPLER:\n",
    "        # Use weighted loss as well for extra emphasis on minority classes\n",
    "        class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        print(\"‚úÖ CrossEntropyLoss with class weights\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(\"‚úÖ CrossEntropyLoss (unweighted)\")\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    print(f\"‚úÖ AdamW optimizer (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "    \n",
    "    # Learning rate scheduler (verbose deprecated in newer PyTorch, removed)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3\n",
    "    )\n",
    "    print(\"‚úÖ ReduceLROnPlateau scheduler (factor=0.5, patience=3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f759adf",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validation\", leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153dc61",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is None:\n",
    "    print(\"‚ùå Cannot train. Dataset not loaded.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üöÄ STARTING TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        print(f\"\\nüìÖ Epoch {epoch+1}/{MAX_EPOCHS}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "        print(f\"   LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save model\n",
    "            model_name = f\"Guava_{MODEL_ARCH}_E{epoch+1}_VAL{val_acc:.2f}.pth\"\n",
    "            model_path = os.path.join(MODEL_SAVE_DIR, model_name)\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'class_names': CLASS_NAMES,\n",
    "                'num_classes': NUM_CLASSES,\n",
    "                'model_arch': MODEL_ARCH\n",
    "            }, model_path)\n",
    "            print(f\"   üíæ Best model saved: {model_name}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"   ‚è≥ No improvement ({patience_counter}/{EARLY_STOPPING_PATIENCE})\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"\\nüõë Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ TRAINING COMPLETE\")\n",
    "    print(f\"   Best Validation Accuracy: {best_val_acc:.2f}% (Epoch {best_epoch})\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21573f",
   "metadata": {},
   "source": [
    "### Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735913da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(history['train_loss']) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Learning rate plot\n",
    "    axes[2].plot(history['learning_rates'], marker='o', color='green')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title('Learning Rate Schedule')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_SAVE_DIR, 'training_curves.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Training curves saved to models/training_curves.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training history to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041bade7",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30cbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is not None and len(history['train_loss']) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä MODEL EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load best model\n",
    "    best_model_files = [f for f in os.listdir(MODEL_SAVE_DIR) if f.startswith('Guava_') and f.endswith('.pth')]\n",
    "    if best_model_files:\n",
    "        # Sort by validation accuracy (extract from filename)\n",
    "        best_model_files.sort(key=lambda x: float(x.split('VAL')[-1].replace('.pth', '')), reverse=True)\n",
    "        best_model_path = os.path.join(MODEL_SAVE_DIR, best_model_files[0])\n",
    "        \n",
    "        checkpoint = torch.load(best_model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"‚úÖ Loaded best model: {best_model_files[0]}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_acc = 100. * (all_preds == all_labels).sum() / len(all_labels)\n",
    "    balanced_acc = 100. * balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"\\nüìà Test Results:\")\n",
    "    print(f\"   Overall Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"   Balanced Accuracy: {balanced_acc:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=CLASS_NAMES)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title('Confusion Matrix - Test Set')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_SAVE_DIR, 'confusion_matrix.png'), dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Confusion matrix saved to models/confusion_matrix.png\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No model to evaluate. Please train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df73c9",
   "metadata": {},
   "source": [
    "---\n",
    "## Export Model for Inference\n",
    "\n",
    "Save the final model in a format suitable for inference (e.g., for the Vue frontend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430be85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES is not None:\n",
    "    # Export model for inference\n",
    "    inference_model_path = os.path.join(MODEL_SAVE_DIR, f\"guava_classifier_{MODEL_ARCH}_final.pth\")\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'class_names': CLASS_NAMES,\n",
    "        'num_classes': NUM_CLASSES,\n",
    "        'model_arch': MODEL_ARCH,\n",
    "        'img_size': (IMG_HEIGHT, IMG_WIDTH),\n",
    "        'normalize_mean': NORMALIZE_MEAN,\n",
    "        'normalize_std': NORMALIZE_STD\n",
    "    }, inference_model_path)\n",
    "    \n",
    "    print(f\"‚úÖ Inference model saved: {inference_model_path}\")\n",
    "    print(f\"\\nüì¶ Model includes:\")\n",
    "    print(f\"   - Model weights\")\n",
    "    print(f\"   - Class names: {CLASS_NAMES}\")\n",
    "    print(f\"   - Image size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "    print(f\"   - Normalization values\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
